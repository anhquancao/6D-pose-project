{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.knn.__init__ import KNearestNeighbor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from lib.network import PoseNet, ConfNet, PoseNetRGBOnly\n",
    "from lib.loss import Loss\n",
    "from lib.transformations import euler_matrix, quaternion_matrix, quaternion_from_matrix\n",
    "from datasets.linemod.dataset import PoseDataset as PoseDataset_linemod\n",
    "import yaml\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from lib.bandit import TS\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = 5\n",
    "objlist = [2, 4, 5, 10, 11]\n",
    "num_points = 500\n",
    "iteration = 4\n",
    "refine_start = False\n",
    "bs = 1\n",
    "dataset_config_dir = 'datasets/linemod/dataset_config'\n",
    "output_result_dir = 'experiments/eval_result/linemod'\n",
    "knn = KNearestNeighbor(1)\n",
    "\n",
    "add_depth_to_output=True\n",
    "true_depth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'trained_models/linemod/pose_noconf_model_10_0.01685108797697043.pth'\n",
    "posenet = PoseNetRGBOnly(num_points = num_points, num_obj = num_objects)\n",
    "posenet.cuda();\n",
    "posenet.load_state_dict(torch.load(model))\n",
    "posenet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "confnet = ConfNet(num_objects)\n",
    "confnet.load_state_dict(torch.load('trained_models/linemod/conf_model_1_0.049375090621032035.pth'))\n",
    "confnet.cuda();\n",
    "confnet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 2 buffer loaded\n",
      "Object 4 buffer loaded\n",
      "Object 5 buffer loaded\n",
      "Object 10 buffer loaded\n",
      "Object 11 buffer loaded\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"./datasets/linemod/Linemod_preprocessed\"\n",
    "\n",
    "\n",
    "testdataset = PoseDataset_linemod('eval', \n",
    "                              num_points, \n",
    "                              False, \n",
    "                              dataset_root, \n",
    "                              0.0, \n",
    "                              refine_start,\n",
    "                              use_true_depth=true_depth)\n",
    "testdataloader = torch.utils.data.DataLoader(testdataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_list = testdataset.get_sym_list()\n",
    "num_points_mesh = testdataset.get_num_points_mesh()\n",
    "criterion = Loss(num_points_mesh, sym_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.024750624233, 0.017249224865, 0.020140358597000002, 0.016462758847999998, 0.017588933422000002]\n"
     ]
    }
   ],
   "source": [
    "diameter = []\n",
    "meta_file = open('{0}/models_info.yml'.format(dataset_config_dir), 'r')\n",
    "meta = yaml.load(meta_file)\n",
    "for obj in objlist:\n",
    "    diameter.append(meta[obj]['diameter'] / 1000.0 * 0.1)\n",
    "print(diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_count = [0 for i in range(num_objects)]\n",
    "num_count = [0 for i in range(num_objects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = TS(500)\n",
    "learner.params = np.load('trained_models/linemod/ts_params.npy')\n",
    "learner.NbPulls = np.load('trained_models/linemod/nbpulls.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.3573 NOT Pass! Lost detection!\n",
      "No.3574 NOT Pass! Lost detection!\n",
      "Object 2 success rate: 0.7691561590688651\n",
      "Object 4 success rate: 0.65\n",
      "Object 5 success rate: 0.6427165354330708\n",
      "Object 10 success rate: 0.9764816556914393\n",
      "Object 11 success rate: 0.9498069498069498\n",
      "ALL success rate: 0.7996515679442509\n"
     ]
    }
   ],
   "source": [
    "fw = open('{0}/eval_result_logs.txt'.format(output_result_dir), 'w')\n",
    "for i, data in enumerate(testdataloader, 0):\n",
    "    points, choose, img, target, model_points, idx = data\n",
    "    \n",
    "    if len(points.size()) == 2:\n",
    "        print('No.{0} NOT Pass! Lost detection!'.format(i))\n",
    "        fw.write('No.{0} NOT Pass! Lost detection!\\n'.format(i))\n",
    "        continue\n",
    "    points, choose, img, target, model_points, idx = Variable(points).cuda(), \\\n",
    "                                                     Variable(choose).cuda(), \\\n",
    "                                                     Variable(img).cuda(), \\\n",
    "                                                     Variable(target).cuda(), \\\n",
    "                                                     Variable(model_points).cuda(), \\\n",
    "                                                     Variable(idx).cuda()\n",
    "#     pred_r, pred_t, pred_c, emb = estimator(img, points, choose, idx)\n",
    "    pred_r, pred_t, pred_c, emb = posenet(img, choose, idx)\n",
    "#     pred_loss = confnet(emb)\n",
    "                \n",
    "    pred_r = pred_r / torch.norm(pred_r, dim=2).view(1, num_points, 1)\n",
    "    pred_c = pred_c.view(bs, num_points)\n",
    "    \n",
    "#     how_max, which_max = torch.max(pred_c, 1)\n",
    "#     how_min, which_min = torch.min(pred_loss, 1) # The model predict the error of each pixel\n",
    "#     choice = np.random.randint(500)\n",
    "    arm = learner.chooseArmToPlay()\n",
    "   \n",
    "    pred_t = pred_t.view(bs * num_points, 1, 3)\n",
    "\n",
    "#     my_r = pred_r[0][which_min[0]].view(-1).cpu().data.numpy()\n",
    "#     my_t = (points.view(bs * num_points, 1, 3) + pred_t)[which_min[0]].view(-1).cpu().data.numpy()\n",
    "#     my_pred = np.append(my_r, my_t)\n",
    "    \n",
    "    my_r = pred_r[0][arm].view(-1).cpu().data.numpy()\n",
    "    my_t = (points.view(bs * num_points, 1, 3) + pred_t)[arm].view(-1).cpu().data.numpy()\n",
    "    my_pred = np.append(my_r, my_t)\n",
    "\n",
    "    \n",
    "    # Here 'my_pred' is the final pose estimation result ('my_r': quaternion, 'my_t': translation)\n",
    "    \n",
    "    model_points = model_points[0].cpu().detach().numpy()\n",
    "    my_r = quaternion_matrix(my_r)[:3, :3]\n",
    "    pred = np.dot(model_points, my_r.T) + my_t\n",
    "    target = target[0].cpu().detach().numpy()\n",
    "    \n",
    "    if idx[0].item() in sym_list:\n",
    "        pred = torch.from_numpy(pred.astype(np.float32)).cuda().transpose(1, 0).contiguous()\n",
    "        target = torch.from_numpy(target.astype(np.float32)).cuda().transpose(1, 0).contiguous()\n",
    "        inds = knn(target.unsqueeze(0), pred.unsqueeze(0))\n",
    "        target = torch.index_select(target, 1, inds.view(-1) - 1)\n",
    "        dis = torch.mean(torch.norm((pred.transpose(1, 0) - target.transpose(1, 0)), dim=1), dim=0).item()\n",
    "    else:\n",
    "        dis = np.mean(np.linalg.norm(pred - target, axis=1))\n",
    "\n",
    "    if dis < diameter[idx[0].item()]:\n",
    "        success_count[idx[0].item()] += 1\n",
    "#         print('No.{0} Pass! Distance: {1}'.format(i, dis))\n",
    "        fw.write('No.{0} Pass! Distance: {1}\\n'.format(i, dis))\n",
    "    else:\n",
    "#         print('No.{0} NOT Pass! Distance: {1}'.format(i, dis))\n",
    "        fw.write('No.{0} NOT Pass! Distance: {1}\\n'.format(i, dis))\n",
    "    num_count[idx[0].item()] += 1\n",
    "    \n",
    "for i in range(num_objects):\n",
    "    print('Object {0} success rate: {1}'.format(objlist[i], float(success_count[i]) / num_count[i]))\n",
    "    fw.write('Object {0} success rate: {1}\\n'.format(objlist[i], float(success_count[i]) / num_count[i]))\n",
    "print('ALL success rate: {0}'.format(float(sum(success_count)) / sum(num_count)))\n",
    "fw.write('ALL success rate: {0}\\n'.format(float(sum(success_count)) / sum(num_count)))\n",
    "fw.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "- 2: \"Bench Vise\"\n",
    "- 4: \"camera\"\n",
    "- 5: \"can\"\n",
    "- 6: \"cat\"\n",
    "- 10: \"eggbox\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recvis",
   "language": "python",
   "name": "recvis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
